2 layered network - epochs: 100, learning rate: 0.001, layer one a: 512, layer two a: 512, layer one f: relu, layer two f: relu
epoch,train_loss,validation_loss
1,1.9371751546859741,1.4732075929641724
2,1.9673045873641968,2.2230944633483887
3,1.7929553985595703,1.3133125305175781
4,1.6002506017684937,2.3773908615112305
5,1.6864402294158936,1.8002636432647705
6,1.633365273475647,1.2786765098571777
7,1.3001340627670288,1.34244966506958
8,1.5140430927276611,1.2234748601913452
9,1.4940075874328613,1.425523281097412
10,1.0663352012634277,0.9889975786209106
11,1.1677687168121338,1.3971949815750122
12,1.2548091411590576,1.1427979469299316
13,1.206743597984314,1.3678630590438843
14,1.0823105573654175,1.440011978149414
15,1.2057979106903076,1.3113882541656494
16,1.294579267501831,1.304748296737671
17,1.2008105516433716,1.2337993383407593
18,1.0193575620651245,1.5140388011932373
19,1.1648027896881104,1.2145767211914062
20,1.0647351741790771,0.8047298192977905
21,1.3549097776412964,1.1070969104766846
22,0.8581134080886841,1.0717778205871582
23,1.028883695602417,1.4748196601867676
24,1.106217384338379,0.7951945662498474
25,1.2346112728118896,1.1903282403945923
26,0.8208221197128296,1.1838818788528442
27,0.9320120811462402,0.9974594712257385
28,1.4065032005310059,0.9494613409042358
29,0.8864121437072754,1.2884482145309448
30,1.0383236408233643,0.8531246185302734
31,0.852713406085968,0.8652439117431641
32,0.9528003931045532,1.441490888595581
33,1.0370227098464966,0.8895188570022583
34,1.4237022399902344,0.9913694858551025
35,1.0939253568649292,1.0748023986816406
36,0.9098212122917175,0.9060472846031189
37,0.9220255017280579,1.0909277200698853
38,0.6857362985610962,1.9387301206588745
39,1.1143770217895508,0.6585263609886169
40,1.119606375694275,1.1488901376724243
41,0.9243588447570801,0.964715838432312
42,0.7504794001579285,0.7837491035461426
43,1.0104074478149414,1.2478938102722168
44,0.9130719900131226,0.6755625009536743
45,1.1188709735870361,1.0767396688461304
46,0.8657979965209961,0.8014950752258301
47,1.0765315294265747,0.9154202938079834
48,1.1736388206481934,1.2049987316131592
49,1.1310395002365112,1.0386056900024414
50,0.9957751035690308,0.6244465112686157
51,0.7113328576087952,1.0114762783050537
52,0.7936290502548218,2.751969814300537
53,0.6618942022323608,0.9232236742973328
54,0.9170473217964172,1.4318797588348389
55,0.7524622082710266,0.7344852685928345
56,0.9888808131217957,1.2515854835510254
57,0.7354944348335266,0.7338497042655945
58,0.7264543771743774,0.708960771560669
59,0.7962039113044739,0.2542482018470764
60,1.1492483615875244,2.064598560333252
61,0.6891089677810669,0.5121179819107056
62,0.6295900344848633,0.5455417037010193
63,0.9119055867195129,0.6827197074890137
64,0.7290893197059631,0.5726538896560669
65,1.033092737197876,0.9824812412261963
66,0.6745980978012085,1.072572112083435
67,0.5436164736747742,1.6014739274978638
68,0.7985459566116333,2.3237366676330566
69,0.904153048992157,1.2254377603530884
70,0.6613269448280334,1.0208724737167358
71,0.9349543452262878,0.9524170160293579
72,0.7631136178970337,1.8625792264938354
73,0.931651771068573,0.8803513646125793
74,1.0244090557098389,0.9097384214401245
75,0.5085960626602173,1.535333275794983
76,0.7919591069221497,1.2480087280273438
77,0.5108176469802856,1.1008851528167725
78,0.7909348011016846,1.0043416023254395
79,0.6493808031082153,2.189955472946167
80,0.7051721811294556,0.9751954078674316
81,0.8095090985298157,1.4884417057037354
82,0.9057881236076355,0.7852236032485962
83,0.6315403580665588,2.3511948585510254
84,0.6376158595085144,0.8304728269577026
85,0.8530200719833374,2.0256195068359375
86,0.8663101196289062,2.1737403869628906
87,0.6764295697212219,0.6224234104156494
88,0.8208964467048645,2.5417869091033936
89,0.6937877535820007,0.5884400010108948
90,0.7197946906089783,2.172013282775879
91,0.7563585042953491,1.4779009819030762
92,0.578487753868103,0.9019265174865723
93,0.46801844239234924,1.1042755842208862
94,1.0651856660842896,0.7615955471992493
95,0.7189816832542419,1.1255204677581787
96,0.6783421635627747,0.635341465473175
97,0.519655168056488,1.4307122230529785
98,0.7721078991889954,1.28963303565979
99,0.9987668991088867,1.1414997577667236
100,0.6269491314888,0.722274661064148
Training correctness: 73.048
Validation correctness: 57.56
